{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7dda9ef8",
   "metadata": {},
   "source": [
    "# PyKale example: Domain Adaptation on Digits with Lightning\n",
    "\n",
    "This example is constructed by refactoring the [ADA: (Yet) Another Domain Adaptation library](https://github.com/criteo-research/pytorch-ada), with many domain adaptation algorithms included.\n",
    "\n",
    "It has been put together to run interactively on online hosting platofrms including [Google Colab](https://colab.research.google.com) or [myBinder](https://mybinder.org), but can also be downloaded and run locally. Follow the [PyKale](https://github.com/pykale/pykale) installation instructions for this.\n",
    "\n",
    "*ToDo: Description of what this example actually does.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277595d5",
   "metadata": {},
   "source": [
    "# Setup\n",
    "\n",
    "The first few blocks of code are necessary to set up the notebook execution environment and import the required modules, including PyKale.\n",
    "\n",
    "This checks if the notebook is running on Google Colab and installs required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5d00e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    print('Running on CoLab')\n",
    "    !pip install pykale[extras] \n",
    "\n",
    "    !git clone -b digits-notebook https://github.com/pykale/pykale.git\n",
    "    %cd pykale/examples/digits_dann_lightn\n",
    "else:\n",
    "    print('Not running on CoLab')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cff6c0",
   "metadata": {},
   "source": [
    "This imports required modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b723d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "from config import get_cfg_defaults\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import SequentialSampler\n",
    "import torchvision\n",
    "\n",
    "from model import get_model\n",
    "\n",
    "from kale.loaddata.digits_access import DigitDataset\n",
    "from kale.loaddata.multi_domain import MultiDomainDatasets\n",
    "from kale.utils.csv_logger import setup_logger\n",
    "from kale.utils.seed import set_seed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6532d78",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "In this example we provide a [default configuration for domain adaptation problems](https://github.com/pykale/pykale/blob/main/examples/digits_dann_lightn/config.py) which  which is tailored using a [`.yaml` file for the specific application in this example](https://github.com/pykale/pykale/blob/main/examples/digits_dann_lightn/configs/TUTORIAL.yaml).\n",
    "\n",
    "If GPUs are to be used at runtime, this is specified using a seperate variable. If you are running this example on Google Colab, or on a machine with GPU support, you might [set this](https://pytorch-lightning.readthedocs.io/en/stable/common/trainer.html#trainer-class-api) to make use of GPU accleration.\n",
    "\n",
    "The configuration is summarised below the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8253f704",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_path = \"./configs/TUTORIAL.yaml\" # Path to `.yaml` config file\n",
    "gpus = None # GPU settings\n",
    "\n",
    "cfg = get_cfg_defaults()\n",
    "cfg.merge_from_file(cfg_path)\n",
    "cfg.freeze()\n",
    "print(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759d55dc",
   "metadata": {},
   "source": [
    "## Setup Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292a0aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(cfg.OUTPUT.DIR, exist_ok=True)\n",
    "format_str = \"@%(asctime)s %(name)s [%(levelname)s] - (%(message)s)\"\n",
    "logging.basicConfig(format=format_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9d0bcd",
   "metadata": {},
   "source": [
    "## Select Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1ae7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "source, target, num_channels = DigitDataset.get_source_target(\n",
    "    DigitDataset(cfg.DATASET.SOURCE.upper()), DigitDataset(cfg.DATASET.TARGET.upper()), cfg.DATASET.ROOT\n",
    ")\n",
    "\n",
    "dataset = MultiDomainDatasets(\n",
    "    source,\n",
    "    target,\n",
    "    config_weight_type=cfg.DATASET.WEIGHT_TYPE,\n",
    "    config_size_type=cfg.DATASET.SIZE_TYPE,\n",
    "    val_split_ratio=cfg.DATASET.VAL_SPLIT_RATIO,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b96eb0",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cc2485",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "seed = cfg.SOLVER.SEED + i * 10\n",
    "# seed_everything in pytorch_lightning did not set torch.backends.cudnn\n",
    "set_seed(seed)\n",
    "print(f\"==> Building model for seed {seed} ......\")\n",
    "# ---- setup model and logger ----\n",
    "model, train_params = get_model(cfg, dataset, num_channels)\n",
    "logger, results, checkpoint_callback, test_csv_file = setup_logger(\n",
    "    train_params, cfg.OUTPUT.DIR, cfg.DAN.METHOD, seed\n",
    ")\n",
    "\n",
    "if gpus is None:\n",
    "    trainer = pl.Trainer(\n",
    "        progress_bar_refresh_rate=cfg.OUTPUT.PB_FRESH,  # in steps\n",
    "        min_epochs=cfg.SOLVER.MIN_EPOCHS,\n",
    "        max_epochs=cfg.SOLVER.MAX_EPOCHS,\n",
    "        callbacks=[checkpoint_callback],\n",
    "        logger=False,\n",
    "    )\n",
    "else:\n",
    "    trainer = pl.Trainer(\n",
    "        progress_bar_refresh_rate=cfg.OUTPUT.PB_FRESH,  # in steps\n",
    "        min_epochs=cfg.SOLVER.MIN_EPOCHS,\n",
    "        max_epochs=cfg.SOLVER.MAX_EPOCHS,\n",
    "        callbacks=[checkpoint_callback],\n",
    "        logger=False,\n",
    "        gpus=gpus,\n",
    "    )\n",
    "\n",
    "trainer.fit(model)\n",
    "results.update(\n",
    "    is_validation=True, method_name=cfg.DAN.METHOD, seed=seed, metric_values=trainer.callback_metrics,\n",
    ")\n",
    "# test scores\n",
    "trainer.test()\n",
    "results.update(\n",
    "    is_validation=False, method_name=cfg.DAN.METHOD, seed=seed, metric_values=trainer.callback_metrics,\n",
    ")\n",
    "results.to_csv(test_csv_file)\n",
    "results.print_scores(cfg.DAN.METHOD)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
