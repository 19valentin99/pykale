{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7723f1ab",
   "metadata": {},
   "source": [
    "# PyKale Tutorial: Domain Adaptation on Digits with Lightning\n",
    "\n",
    "| [Open in Colab](https://colab.research.google.com/github/pykale/pykale/blob/main/examples/digits_dann_lightn/tutorial.ipynb) (click `Runtime-->Run all (Ctrl+F9`) | [Launch Binder](https://mybinder.org/v2/gh/pykale/pykale/HEAD?filepath=examples%2Fdigits_dann_lightn%2Ftutorial.ipynb) (click `Cell-->Run All`) |\n",
    "\n",
    "This tutorial is constructed based on the `digits_dann_lightn` example `main.py`, which is in turn refactored from the [ADA: (Yet) Another Domain Adaptation library](https://github.com/criteo-research/pytorch-ada).\n",
    "\n",
    "It has been put together to run interactively on online hosting platforms including [Google Colab](https://colab.research.google.com) or [myBinder](https://mybinder.org), but can also be downloaded and run locally. Follow the [PyKale installation instructions](https://pykale.readthedocs.io/en/latest/installation.html) for this.\n",
    "\n",
    "[Domain Adaptation](https://en.wikipedia.org/wiki/Domain_adaptation) takes a model trained and evaluated on one set of data (the source) and adapts it to another (the target). In this tutorial, a model is trained on one Digits Dataset (source) and adapted to another (target)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df7b3f70",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "The first few blocks of code are necessary to set up the notebook execution environment and import the required modules, including PyKale.\n",
    "\n",
    "This checks if the notebook is running on Google Colab and installs required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149c5f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'google.colab' in str(get_ipython()):\n",
    "    print('Running on CoLab')\n",
    "    !pip uninstall --yes imgaug && pip uninstall --yes albumentations && pip install git+https://github.com/aleju/imgaug.git\n",
    "    !pip install git+https://github.com/pykale/pykale.git\n",
    "\n",
    "    !git clone https://github.com/pykale/pykale.git\n",
    "    %cd pykale/examples/digits_dann_lightn\n",
    "else:\n",
    "    print('Not running on CoLab')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2161d4",
   "metadata": {},
   "source": [
    "This imports required modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa68c940",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed while importing qhull: 找不到指定的模块。",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_17344/4145449791.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mpytorch_lightning\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcallbacks\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mModelCheckpoint\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     14\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 15\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mkale\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mloaddata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdigits_access\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mDigitDataset\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     16\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mkale\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mloaddata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmulti_domain\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mMultiDomainDatasets\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     17\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mkale\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mutils\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mseed\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mset_seed\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32me:\\out\\python\\pt\\pykale\\kale\\loaddata\\digits_access.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mtorchvision\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdatasets\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mMNIST\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mSVHN\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 11\u001B[1;33m \u001B[1;32mimport\u001B[0m \u001B[0mkale\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mprepdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mimage_transform\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mimage_transform\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     12\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mkale\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mloaddata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdataset_access\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mDatasetAccess\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[0mkale\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mloaddata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmnistm\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mMNISTM\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32me:\\out\\python\\pt\\pykale\\kale\\prepdata\\image_transform.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     12\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mnumpy\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mtorchvision\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtransforms\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mtransforms\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 14\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mskimage\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtransform\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mestimate_transform\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mrescale\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mwarp\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     15\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     16\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\software\\Anaconda3\\envs\\pt\\lib\\site-packages\\skimage\\transform\\__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m from .hough_transform import (hough_line, hough_line_peaks,\n\u001B[0m\u001B[0;32m      2\u001B[0m                               \u001B[0mprobabilistic_hough_line\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mhough_circle\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m                               hough_circle_peaks, hough_ellipse)\n\u001B[0;32m      4\u001B[0m from .radon_transform import (radon, iradon, iradon_sart,\n\u001B[0;32m      5\u001B[0m                               order_angles_golden_ratio)\n",
      "\u001B[1;32mD:\\software\\Anaconda3\\envs\\pt\\lib\\site-packages\\skimage\\transform\\hough_transform.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mnumpy\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 2\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[0mscipy\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mspatial\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mcKDTree\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      3\u001B[0m from ._hough_transform import (_hough_circle,\n\u001B[0;32m      4\u001B[0m                                \u001B[0m_hough_ellipse\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m                                \u001B[0m_hough_line\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mD:\\software\\Anaconda3\\envs\\pt\\lib\\site-packages\\scipy\\spatial\\__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     96\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[1;33m.\u001B[0m\u001B[0mkdtree\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[1;33m*\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     97\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[1;33m.\u001B[0m\u001B[0mckdtree\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[1;33m*\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 98\u001B[1;33m \u001B[1;32mfrom\u001B[0m \u001B[1;33m.\u001B[0m\u001B[0mqhull\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[1;33m*\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     99\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[1;33m.\u001B[0m\u001B[0m_spherical_voronoi\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[0mSphericalVoronoi\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    100\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[1;33m.\u001B[0m\u001B[0m_plotutils\u001B[0m \u001B[1;32mimport\u001B[0m \u001B[1;33m*\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mImportError\u001B[0m: DLL load failed while importing qhull: 找不到指定的模块。"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "\n",
    "from config import get_cfg_defaults\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import SequentialSampler\n",
    "import torchvision\n",
    "\n",
    "from model import get_model\n",
    "from pytorch_lightning import loggers as pl_loggers\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "from kale.loaddata.digits_access import DigitDataset\n",
    "from kale.loaddata.multi_domain import MultiDomainDatasets\n",
    "from kale.utils.seed import set_seed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ddfee2",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "In this tutorial we provide a [default configuration for domain adaptation problems](https://github.com/pykale/pykale/blob/main/examples/digits_dann_lightn/config.py), which is tailored using a [`.yaml` file for the specific application in this tutorial](https://github.com/pykale/pykale/blob/main/examples/digits_dann_lightn/configs/TUTORIAL.yaml).\n",
    "\n",
    "If GPUs are to be used at runtime, this is specified using a separate variable. If you are running this tutorial on Google Colab, or on a machine with GPU support, you might [set this](https://pytorch-lightning.readthedocs.io/en/stable/common/trainer.html#trainer-class-api) to make use of GPU acceleration. (On Google Colab click Runtime->Manage Sessions and select GPU, then change to `gpus = 1`).\n",
    "\n",
    "The configuration is summarized below the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee1621c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg_path = \"./configs/tutorial.yaml\" # Path to `.yaml` config file\n",
    "gpus = None # GPU settings\n",
    "\n",
    "cfg = get_cfg_defaults()\n",
    "cfg.merge_from_file(cfg_path)\n",
    "cfg.freeze()\n",
    "print(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5e8956",
   "metadata": {},
   "source": [
    "## Select Datasets\n",
    "\n",
    "Source and target datasets are specified using `DigitDataset.get_source_target` from values in the configuration (`cfg`) above. In this tutorial, we specify a subset of classes (1, 3 and 8) to make training and testing quicker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d76d33c",
   "metadata": {},
   "outputs": [],
   "source": [
    "source, target, num_channels = DigitDataset.get_source_target(\n",
    "    DigitDataset(cfg.DATASET.SOURCE.upper()), DigitDataset(cfg.DATASET.TARGET.upper()), cfg.DATASET.ROOT\n",
    ")\n",
    "\n",
    "class_subset = [1, 3, 8]\n",
    "\n",
    "dataset = MultiDomainDatasets(\n",
    "    source,\n",
    "    target,\n",
    "    config_weight_type=cfg.DATASET.WEIGHT_TYPE,\n",
    "    config_size_type=cfg.DATASET.SIZE_TYPE,\n",
    "    val_split_ratio=cfg.DATASET.VAL_SPLIT_RATIO,\n",
    "    class_ids=class_subset,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7287c453",
   "metadata": {},
   "source": [
    "## Set Seed\n",
    "\n",
    "Some algorithms used in model training require generation of pseudo-random numbers. Setting the seed from which these are generated ensures reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4671a273",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "seed = cfg.SOLVER.SEED\n",
    "# seed_everything in pytorch_lightning did not set torch.backends.cudnn\n",
    "set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1ea047",
   "metadata": {},
   "source": [
    "## Setup Model\n",
    "\n",
    "Here, we use the previously defined configuration and dataset to set up the model we will subsequently train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e688dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time model, train_params = get_model(cfg, dataset, num_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634b3624",
   "metadata": {},
   "source": [
    "Output reports on data file use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c3661d",
   "metadata": {},
   "source": [
    "## Setup Logger\n",
    "\n",
    "A Tensorboard logger is used to store output generated during model training. This information can be used to assess the effectiveness of the training and to identify problems. The output model is also stored in `cfg.OUTPUT.TB_DIR`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0780abba",
   "metadata": {},
   "outputs": [],
   "source": [
    "tb_logger = pl_loggers.TensorBoardLogger(cfg.OUTPUT.TB_DIR, name=\"seed{}\".format(seed))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcd8d8a",
   "metadata": {},
   "source": [
    "## Setup Checkpoint\n",
    "\n",
    "A ModelCheckpoint is used to save the model periodically by monitoring a quantity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3a1459",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(filename=\"{epoch}-{step}-{val_loss:.4f}\", monitor=\"val_loss\", mode=\"min\",)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2b1052",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Setup Trainer\n",
    "\n",
    "A trainer object is used to determine and store model parameters. Here, one is configured with information on how a model should be trained, and what hardware will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b82fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(\n",
    "    progress_bar_refresh_rate=cfg.OUTPUT.PB_FRESH,  # in steps\n",
    "    min_epochs=cfg.SOLVER.MIN_EPOCHS,\n",
    "    max_epochs=cfg.SOLVER.MAX_EPOCHS,\n",
    "    callbacks=[checkpoint_callback],\n",
    "    logger=False,\n",
    "    gpus=gpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a334e805",
   "metadata": {},
   "source": [
    "Output reports on available GPU and TPU resources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef361758",
   "metadata": {},
   "source": [
    "## Train Model\n",
    "\n",
    "Optimize model parameters using the trainer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100b404d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time trainer.fit(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b8f7a9",
   "metadata": {},
   "source": [
    "## Test Optimized Model\n",
    "\n",
    "Check performance of model optimized with training data against test data which was not used in training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad99fab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test scores\n",
    "%time trainer.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabc1b70",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Outputs are defined as:\n",
    "\n",
    "* 'Te_domain_acc': Accuracy on classifying the domain (source or target) from which data came.\n",
    "* 'Te_source_acc': Accuracy on test data drawn from the source dataset.\n",
    "* 'Te_target_acc': Accuracy on test data drawn from the target dataset.\n",
    "* 'test_loss': Loss function value on the test data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (pykale)",
   "language": "python",
   "name": "pycharm-c0f5a7c0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
